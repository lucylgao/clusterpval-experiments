quiz_res2$AdjTotal2[is.na(quiz_res2$AdjTotal2)] <- 0
quiz_res2$Quiz2 <- quiz_res2$AdjTotal2/10
quiz_res3 <- read.csv("~/Downloads/quiz-3-c0541-marks.csv")
quiz_res3 <- quiz_res3[, c(5, 13)]
names(quiz_res3) <- c( "Id", "AdjTotal3")
quiz_res3$AdjTotal3[is.na(quiz_res3$AdjTotal3)] <- 0
quiz_res3$Quiz3 <- quiz_res3$AdjTotal3/8
quiz_res4 <- read.csv("~/Downloads/quiz-4-426fb-marks.csv")
quiz_res4 <- quiz_res4[, c(5, 13)]
names(quiz_res4) <- c("Id", "AdjTotal4")
quiz_res4$AdjTotal4[is.na(quiz_res4$AdjTotal4)] <- 0
quiz_res4$Quiz4 <- quiz_res4$AdjTotal4/10
quiz_res5 <- read.csv("~/Downloads/quiz-5-7004c-marks.csv")
quiz_res5 <- quiz_res5[, c(5, 13)]
names(quiz_res5) <- c("Id", "AdjTotal5")
quiz_res5$AdjTotal5[is.na(quiz_res5$AdjTotal5)] <- 0
quiz_res5$Quiz5 <- quiz_res5$AdjTotal5/10
quiz_res6 <- read.csv("~/Downloads/quiz-6-a9b83-marks.csv")
quiz_res6 <- quiz_res6[, c(5, 14)]
names(quiz_res6) <- c("Id", "AdjTotal6")
quiz_res6$AdjTotal6[is.na(quiz_res6$AdjTotal6)] <- 0
quiz_res6$Quiz6 <- quiz_res6$AdjTotal6/9
assignment1 <- read.csv("~/Downloads/assignment-1-ee501-marks (3).csv")
assignment1 <- assignment1[, c(5,  17)]
names(assignment1) <- c("Id",  "AdjAssignmentTotal")
assignment1$AdjAssignmentTotal[is.na(assignment1$AdjAssignmentTotal)] <- 0
assignment1$Assignment1 <- assignment1$AdjAssignmentTotal/50
quiz_results <- merge(results, quiz_res1, all.x=TRUE, by="Id")
quiz_results <- quiz_results[, c(1, 14, 15)]
quiz_results <- merge(quiz_results, quiz_res2, all.x = TRUE, by="Id")
quiz_results <- merge(quiz_results, quiz_res3, all.x = TRUE, by="Id")
quiz_results <- merge(quiz_results, quiz_res4, all.x = TRUE, by="Id")
quiz_results <- merge(quiz_results, quiz_res5, all.x = TRUE, by="Id")
quiz_results <- merge(quiz_results, quiz_res6, all.x = TRUE, by="Id")
quiz_results <- merge(quiz_results, assignment1, all.x = TRUE, by="Id")
#quiz_results$Quiz1[is.na(quiz_results$Quiz1)] <- 0
quiz_results$crude_total <-
((quiz_results$Quiz1 + quiz_results$Quiz2+quiz_results$Quiz3+quiz_results$Quiz4 + quiz_results$Quiz5 + quiz_results$Quiz6)/6)*24 + quiz_results$Assignment1*20
hist(quiz_results$crude_total)
summary(quiz_results$crude_total)
# results_dl <- read.csv("~/Downloads/STAT 330 - Spring 2021_GradesExport_2021-07-13-17-33.csv")
# summary(((quiz_results$AdjTotal1/10+quiz_results$AdjTotal2/10 + quiz_results$AdjTotal3/8 +
#            quiz_results$AdjTotal4/10)/4)*(4*4) +
#           (quiz_results$AdjAssignmentTotal/50)*20)/(16 + 20)
#
# hist((((quiz_results$AdjTotal1/10+quiz_results$AdjTotal2/10 + quiz_results$AdjTotal3/8 +
#             quiz_results$AdjTotal4/10)/4)*20 +
#           (quiz_results$AdjAssignmentTotal/50)*20)/40)
#
# quantile(((quiz_results$AdjTotal1/10+quiz_results$AdjTotal2/10 + quiz_results$AdjTotal3/8 +
#              quiz_results$AdjTotal4/10)/4)*20 +
#            (final_results$AdjAssignmentTotal/50)*20, seq(0, 1, by=0.1), na.rm=TRUE)
#
#
# hist((quiz_results$AdjTotal1/10+quiz_results$AdjTotal2/10 + quiz_results$AdjTotal3/8 +
#            quiz_results$AdjTotal4/10)/4)
37.07/44
results_dl <- read.csv("~/Downloads/STAT 330 - Spring 2021_GradesExport_2021-07-13-17-33.csv")
summary(results_dl$Assignment.1.Points.Grade..Numeric.MaxPoints.50.Weight.20.)
summary(assignment1$Assignment1)
summary(assignment1$Assignment1)*50
nrow(assignment1)
nrow(resuts_dl)
nrow(results_dl)
nrow(quiz_results)
summary(quiz_results$Assignment1)
summary(quiz_results$AdjAssignmentTotal)
43.37/50
which(is.na(results_dl$Assignment.1.Points.Grade..Numeric.MaxPoints.50.Weight.20.))
results_dl[c(1, 2, 4, 84, 211), ]
usethis::use_blank_slate()
prefinal_grades <- read.csv("~/Downloads/STAT 330 - Winter 2021_GradesExport_2021-04-23-21-12.csv")
prefinal_grades[prefinal_grades$OrgDefinedId == "#20844372", 30] <- prefinal_grades[prefinal_grades$OrgDefinedId == "#20844372", 30] +
(25.5/30)*25 # Manually putting in Sheila Jang's Alternate Time MIdterm
submit <- read.csv("~/Downloads/STAT-330-041.csv", header=F)
submit$V1 <- paste("#", submit$V1, sep="")
names(submit) <- c("id", "V2", "V3", "V4", "V5", "V6", "V7", "V8")
before <- prefinal_grades[, c(1, 30)]
names(before) <- c("id", "allbutfinal")
before[before$id == "#20723967", ]$allbutfinal <- 10 + (((10.75/11) + 8/10 + 3*1 + 7/8 + 7.25/10)/7)*40 + (19/30)*25 # Manually putting in Hyejeong Yoon's accomodations
merge_both <- merge(submit, before, by.x=c("id"))
final <- read.csv("~/Downloads/final-exam-9ae59-marks (2).csv")
final_processed <- final[, c(5, 20)]
final_processed$Student.ID.Number <- paste("#", final_processed$Student.ID.Number, sep="")
names(final_processed) <- c("id", "final")
merge_all <- merge(merge_both, final_processed, by.x=c("id"))
dim(merge_all)
summary(merge_all$final)
merge_all$final[is.na(merge_all$final)] <- 0 # Convert NA's to 0's
merge_all$V6 <- merge_all$allbutfinal + (merge_all$final/45)*25
summary(merge_all$V6)
merge_all$V6[52] <- merge_all$allbutfinal[52] + (merge_all$final[52]/45)*50 # Manually doing Yansen Zheng's accommodated missed midterm
merge_all[merge_all$V6 < 50, ] # No letter grades of 47, 48, or 49
merge_all[merge_all$id == 20828904, ]
merge_all[merge_all$id == #20828904, ]
]
merge_all[merge_all$id == "20828904", ]
merge_all[merge_all$id == "#20828904", ]
median(final_grades$V6)
final_grades <- merge_all[, 1:8]
final_grades$id <- sapply(final_grades$id, function(x) strsplit(x, "#")[[1]][2])
final_grades$V6 <- round(final_grades$V6)
median(final_grades$V6)
quantile(final_grades$V6)
mean(final_grades$V6 >= 95)
mean(merge_all$final >= 38)
# set seed
set.seed(1)
# generate data
a = 1
b = 1
n = 100
p = 10
q <- 2
sigma_y <- 0.25
X <- MASS::mvrnorm(n, rep(0,p), diag(rep(1,p)))
W <- (2*X[, 1] - X[, 3]) + MASS::mvrnorm(n, rep(0,q), diag(rep(0.5,q)))
beta <- rep(1, q)
mu_y <- b*I(X[,1] < 0) +
b*a*(I(X[,1] < 0 & X[,2] > 0)) +
b*I(X[,3] < 0 & X[,2] < 0 & X[,1] < 0)+
b*I(X[,3] > 0 & X[,2] > 0 & X[,1] < 0) + W%*%beta
W
cor(W[, 1], X[, 1])
cor(W[, 1], X[, 3])
cor(W[, 1], X[, 2])
cor(W[, 1], X[, 5])
cor(W[, 1], X[, 6])
cor(W[, 1], X[, 7])
cor(W[, 1], X[, 5])
cor(W[, 1], X[, 6])
cor(W[, 1], X[, 7])
cor(W[, 1], X[, 2])
cbind(mu_y, b*I(X[,1] < 0) +
b*a*(I(X[,1] < 0 & X[,2] > 0)) +
b*I(X[,3] < 0 & X[,2] < 0 & X[,1] < 0)+
b*I(X[,3] > 0 & X[,2] > 0 & X[,1] < 0))
summary(W)
W <- (X[, 1] - 0.5X[, 3]) + MASS::mvrnorm(n, rep(0,q), diag(rep(0.5,q)))
W <- (X[, 1] - 0.5*X[, 3]) + MASS::mvrnorm(n, rep(0,q), diag(rep(0.5,q)))
summary(W)
summary(b*I(X[,1] < 0) +
b*a*(I(X[,1] < 0 & X[,2] > 0)) +
b*I(X[,3] < 0 & X[,2] < 0 & X[,1] < 0)+
b*I(X[,3] > 0 & X[,2] > 0 & X[,1] < 0))
# set seed
set.seed(1)
# generate data
a = 1
b = 1
n = 100
p = 10
q <- 2
sigma_y <- 0.25
X <- MASS::mvrnorm(n, rep(0,p), diag(rep(1,p)))
W <- (0.25*X[, 1] - 0.5*X[, 3]) + MASS::mvrnorm(n, rep(0,q), diag(rep(0.5,q)))
beta <- rep(1, q)
mu_y <- b*I(X[,1] < 0) +
b*a*(I(X[,1] < 0 & X[,2] > 0)) +
b*I(X[,3] < 0 & X[,2] < 0 & X[,1] < 0)+
b*I(X[,3] > 0 & X[,2] > 0 & X[,1] < 0) + W%*%beta
summary(W)
cbind(b*I(X[,1] < 0) +
b*a*(I(X[,1] < 0 & X[,2] > 0)) +
b*I(X[,3] < 0 & X[,2] < 0 & X[,1] < 0)+
b*I(X[,3] > 0 & X[,2] > 0 & X[,1] < 0), b*I(X[,1] < 0) +
b*a*(I(X[,1] < 0 & X[,2] > 0)) +
b*I(X[,3] < 0 & X[,2] < 0 & X[,1] < 0)+
b*I(X[,3] > 0 & X[,2] > 0 & X[,1] < 0) + W%*%beta)
plot(b*I(X[,1] < 0) +
b*a*(I(X[,1] < 0 & X[,2] > 0)) +
b*I(X[,3] < 0 & X[,2] < 0 & X[,1] < 0)+
b*I(X[,3] > 0 & X[,2] > 0 & X[,1] < 0), b*I(X[,1] < 0) +
b*a*(I(X[,1] < 0 & X[,2] > 0)) +
b*I(X[,3] < 0 & X[,2] < 0 & X[,1] < 0)+
b*I(X[,3] > 0 & X[,2] > 0 & X[,1] < 0) + W%*%beta)
# set seed
set.seed(1)
# generate data
a = 1
b = 1
n = 100
p = 10
q <- 2
sigma_y <- 0.25
X <- MASS::mvrnorm(n, rep(0,p), diag(rep(1,p)))
W <- (0.25*X[, 1] - 0.5*X[, 3]) + MASS::mvrnorm(n, rep(0,q), diag(rep(0.5,q)))
beta <- rep(1, q)
mu_y <- b*I(X[,1] < 0) +
b*a*(I(X[,1] < 0 & X[,2] > 0)) +
b*I(X[,3] < 0 & X[,2] < 0 & X[,1] < 0)+
b*I(X[,3] > 0 & X[,2] > 0 & X[,1] < 0) + W%*%beta
Y <- rnorm(n,mu_y,sigma_y)
dat <- data.frame(Y=Y,X=X,W=W)
nameX <- sapply(1:p, function(u) paste0("X",u))
nameW <- sapply(1:q, function(u) paste0("W",u))
names(dat) = c("Y", nameX, nameW)
# partition data into training and test datasets
# dtrain: data.frame for the training set
# dtest: data.frame for the test set
pda <- sample.int(n = nrow(dat), size = floor(.8*nrow(dat)), replace = F)
train <- dat[pda,]
test <- dat[-pda,]
trainX <- as.matrix(train[, nameX])
trainW <- as.matrix(train[, nameW])
trainy <- as.numeric(train[, "Y"])
testX <- as.matrix(test[, nameX])
testW <- as.matrix(test[, nameW])
testy <- as.numeric(test[, "Y"])
library(spatRF)
library(rpart)
# define the identity matrix
# M: residual maker matrix
M <- diag(nrow(trainW)) - trainW %*% solve(t(trainW) %*% trainW) %*% t(trainW)
caCART <- spatTree(trainy, trainX, i.Sig = M, max.depth=4, m=ncol(trainX))
betahat <- solve(t(trainW) %*% trainW)%*%t(trainW)%*%(trainy - caCART$Ck %*% caCART$muk)
makeCmat <- function(mod,X,domain){
num.branches <- length(mod$covar)
n <- dim(X)[1]
d <- length(unique(domain))
Ck <- matrix(0,n,d*(num.branches+1))
Ck[cbind(1:n,domain)] <- 1
leaf.mem <- rep(1,n)
for (a in 1:num.branches){
Ca <- as.numeric(as.numeric(X[,mod$covar[a]]) <= mod$split[a] & leaf.mem==mod$leaf[a])
Ck[cbind(which(Ca==1),a*d+domain[which(Ca==1)])] <- 1
leaf.mem[which(Ca==1)] <- a+1
}
return(Ck)
}
C_new <- makeCmat(caCART, testX, domain = rep(1,length(Y)))
predicty <- C_new%*% caCART$muk + testW%*%betahat
plot(testy, predicty, xlab="Truth", ylab="Prediction", main="Test set, caCART")
abline(0, 1, col="red")
sqrt(sum((testy - predicty)^2)/length(testy)) # RMSE
train_CART <- rpart(Y ~ ., data = train[, c("Y", nameX)])
predicty_CART <- predict(train_CART, newdata=test)
plot(testy, as.numeric(predicty_CART), xlab="Truth", ylab="Prediction", main="Test set, CART")
abline(0, 1, col="red")
sqrt(sum((testy - predicty_CART)^2)/length(testy)) # RMSE
beta
betahat
caCART$muk
table(b*I(X[,1] < 0) +
b*a*(I(X[,1] < 0 & X[,2] > 0)) +
b*I(X[,3] < 0 & X[,2] < 0 & X[,1] < 0)+
b*I(X[,3] > 0 & X[,2] > 0 & X[,1] < 0))
summary(C_new%*% caCART$muk)
table(C_new%*% caCART$muk)
C_new%*% caCART$muk
table(b*I(X[,1] < 0) +
b*a*(I(X[,1] < 0 & X[,2] > 0)) +
b*I(X[,3] < 0 & X[,2] < 0 & X[,1] < 0)+
b*I(X[,3] > 0 & X[,2] > 0 & X[,1] < 0))
# set seed
set.seed(1)
# generate data
a = 1
b = 1
n = 100
p = 10
q <- 2
sigma_y <- 0.25
X <- MASS::mvrnorm(n, rep(0,p), diag(rep(1,p)))
W <- (0.25*X[, 1] - 0.5*X[, 3]) + MASS::mvrnorm(n, rep(0,q), diag(rep(0.5,q)))
beta <- rep(1, q)
mu_y <- b*I(X[,1] < 0) +
b*a*(I(X[,1] < 0 & X[,2] > 0)) +
b*I(X[,3] < 0 & X[,2] < 0 & X[,1] < 0)+
b*I(X[,3] > 0 & X[,2] > 0 & X[,1] < 0) + W%*%beta
Y <- rnorm(n,mu_y,sigma_y)
dat <- data.frame(Y=Y,X=X,W=W)
nameX <- sapply(1:p, function(u) paste0("X",u))
nameW <- sapply(1:q, function(u) paste0("W",u))
names(dat) = c("Y", nameX, nameW)
# partition data into training and test datasets
# dtrain: data.frame for the training set
# dtest: data.frame for the test set
pda <- sample.int(n = nrow(dat), size = floor(.8*nrow(dat)), replace = F)
train <- dat[pda,]
test <- dat[-pda,]
trainX <- as.matrix(train[, nameX])
trainW <- as.matrix(train[, nameW])
trainy <- as.numeric(train[, "Y"])
testX <- as.matrix(test[, nameX])
testW <- as.matrix(test[, nameW])
testy <- as.numeric(test[, "Y"])
library(spatRF)
library(rpart)
# define the identity matrix
# M: residual maker matrix
M <- diag(nrow(trainW)) - trainW %*% solve(t(trainW) %*% trainW) %*% t(trainW)
caCART <- spatTree(trainy, trainX, i.Sig = M, max.depth=3, m=ncol(trainX))
betahat <- solve(t(trainW) %*% trainW)%*%t(trainW)%*%(trainy - caCART$Ck %*% caCART$muk)
makeCmat <- function(mod,X,domain){
num.branches <- length(mod$covar)
n <- dim(X)[1]
d <- length(unique(domain))
Ck <- matrix(0,n,d*(num.branches+1))
Ck[cbind(1:n,domain)] <- 1
leaf.mem <- rep(1,n)
for (a in 1:num.branches){
Ca <- as.numeric(as.numeric(X[,mod$covar[a]]) <= mod$split[a] & leaf.mem==mod$leaf[a])
Ck[cbind(which(Ca==1),a*d+domain[which(Ca==1)])] <- 1
leaf.mem[which(Ca==1)] <- a+1
}
return(Ck)
}
C_new <- makeCmat(caCART, testX, domain = rep(1,length(Y)))
predicty <- C_new%*% caCART$muk + testW%*%betahat
plot(testy, predicty, xlab="Truth", ylab="Prediction", main="Test set, caCART")
abline(0, 1, col="red")
sqrt(sum((testy - predicty)^2)/length(testy)) # RMSE
train_CART <- rpart(Y ~ ., data = train[, c("Y", nameX)])
predicty_CART <- predict(train_CART, newdata=test)
plot(testy, as.numeric(predicty_CART), xlab="Truth", ylab="Prediction", main="Test set, CART")
abline(0, 1, col="red")
sqrt(sum((testy - predicty_CART)^2)/length(testy)) # RMSE
summary(C_new%*% caCART$muk)
table(C_new%*%caCART$muk)
mean(runif(10000, -5, 5))
mean(runif(10000, -5, 5)^2)
(5^4 + 5^2)/(2*5 + 1)
sqrt((5^4 + 5^2)/(2*5 + 1))
1/(2*5 + 1) + 2^2/(2*5 + 1) + 3^2/(2*5 + 1) + 4^2/(2*5 + 1) + 5^2/(2*5 + 1)
5*4/2
1 + 2^2 + 3^2 + 4^2 + 5^2
55/(2*5 + 1)
5^2(5^2 -1)/2
5^2*(5^2 -1)/2
5*(5+1)/3
mean(runif(100000, -5, 5)^2)
mean(sample(10000, seq(-5, 5, by=1))^2)
mean(sample(seq(-5, 5, by=1), 10000, replace=TRUE)^2)
x <- rnorm(100)
x <- rnorm(100)
y <- x + 1
x <- rnorm(100)
y <- x + 1 + 0.5*rnorm(100)
plot(x, y)
plot(x[sample(1:100, replace=TRUE)], y)
lm(y ~ x[sample(1:100, replace=TRUE)])
attributes(lm(y ~ x[sample(1:100, replace=TRUE)])  )
lm(y ~ x[sample(1:100, replace=TRUE)])$coefficients
x <- rnorm(100)
y <- x + 1 + 0.5*rnorm(100)
plot(x, y)
plot(x[sample(1:100, replace=TRUE)], y)
do_one_sim <- function() {
lm(y ~ x[sample(1:100, replace=TRUE)])$coefficients[2]
}
results <- replicate(1000, do_one_sim())
summary(results)
hist(resulst)
hist(results)
x <- rnorm(100)
y <- x^2 + 1 + 0.5*rnorm(100)
plot(x, y)
plot(x[sample(1:100, replace=TRUE)], y)
do_one_sim <- function() {
lm(y ~ x[sample(1:100, replace=TRUE)])$coefficients[2]
}
results <- replicate(1000, do_one_sim())
hist(results)
plot(x, y)
x <- rnorm(100)
y <- e^x + 1 + 0.5*rnorm(100)
plot(x, y)
plot(x[sample(1:100, replace=TRUE)], y)
do_one_sim <- function() {
lm(y ~ x[sample(1:100, replace=TRUE)])$coefficients[2]
}
results <- replicate(1000, do_one_sim())
hist(results)
plot(x, y)
x <- rnorm(100)
y <- x + 1 + 0.5*rnorm(100)
plot(x, y)
plot(x[sample(1:100, replace=TRUE)], y)
do_one_sim <- function() {
lm(y ~ x[sample(1:100, replace=TRUE)])$coefficients[2]
}
results <- replicate(1000, do_one_sim())
hist(results)
plot(x[sample(1:100, replace=TRUE)], y)
plot(x, y)
plot(x[sample(1:100, replace=TRUE)], y)
eps <- 0.5
n=200
p=80
W <- c(seq(0,4), rep(0,p-5))
nTrials <- 5000
pvals <- matrix(0, nrow=nTrials, ncol=6)
print(i)
set.seed(i)
### True data generating mechanism-- poisson latent variable,
#### genes 2-5 are important, add poisson random noise.
X <- rpois(n, 1)%*%t(W)+matrix(rpois(n*p,3), nrow=n)
Xtilde <- apply(X,2,function(u) rbinom(n=length(u), size=u, p=1-eps))
Xtest <- X-Xtilde
i <- 1
print(i)
set.seed(i)
### True data generating mechanism-- poisson latent variable,
#### genes 2-5 are important, add poisson random noise.
X <- rpois(n, 1)%*%t(W)+matrix(rpois(n*p,3), nrow=n)
Xtilde <- apply(X,2,function(u) rbinom(n=length(u), size=u, p=1-eps))
Xtest <- X-Xtilde
plot(svd(X)$u[, 1], svd(Xtilde)$u[, 1]))
plot(svd(X)$u[, 1], svd(Xtilde)$u[, 1])
rank(svd(X)$u[, 1])
plot(rank(svd(X)$u[, 1]), rank(svd(Xtilde)$u[, 1]))
order(svd(X)$u[, 1])
order(svd(Xtilde)$u[, 1])
setwd("~/Dropbox/My-Research/Lucy-Dissertation/Clustering-Selective-Inference/R-Code/paper-code/")
library(clusterpval)
library(fastcluster)
library(DropletUtils)
library(scater)
library(ggfortify)
library(patchwork)
source("./real-data-code/util.R")
##### Pre-processing data ####
cd4.t <- read10xCounts("./real-data-code/raw/filtered_matrices_mex_memory/hg19")
cd4.t
prefinal_grades <- read.csv("~/Downloads/STAT 330 - Winter 2021_GradesExport_2021-04-23-21-12.csv")
prefinal_grades[prefinal_grades$OrgDefinedId == "#20844372", 30] <- prefinal_grades[prefinal_grades$OrgDefinedId == "#20844372", 30] +
(25.5/30)*25 # Manually putting in Sheila Jang's Alternate Time MIdterm
submit <- read.csv("~/Downloads/STAT-330-041.csv", header=F)
submit$V1 <- paste("#", submit$V1, sep="")
names(submit) <- c("id", "V2", "V3", "V4", "V5", "V6", "V7", "V8")
before <- prefinal_grades[, c(1, 30)]
names(before) <- c("id", "allbutfinal")
before[before$id == "#20723967", ]$allbutfinal <- 10 + (((10.75/11) + 8/10 + 3*1 + 7/8 + 7.25/10)/7)*40 + (19/30)*25 # Manually putting in Hyejeong Yoon's accomodations
merge_both <- merge(submit, before, by.x=c("id"))
final <- read.csv("~/Downloads/final-exam-9ae59-marks (2).csv")
final_processed <- final[, c(5, 20)]
final_processed$Student.ID.Number <- paste("#", final_processed$Student.ID.Number, sep="")
names(final_processed) <- c("id", "final")
merge_all <- merge(merge_both, final_processed, by.x=c("id"))
dim(merge_all)
summary(merge_all$final)
merge_all$final[is.na(merge_all$final)] <- 0 # Convert NA's to 0's
merge_all$V6 <- merge_all$allbutfinal + (merge_all$final/45)*25
summary(merge_all$V6)
merge_all$V6[52] <- merge_all$allbutfinal[52] + (merge_all$final[52]/45)*50 # Manually doing Yansen Zheng's accommodated missed midterm
merge_all[merge_all$V6 < 50, ] # No letter grades of 47, 48, or 49
merge_all[merge_all$V8 == "Anan", ]
merge_all[merge_all$id == "#20830873", ]
25.75/45
25.75/45
setwd("~/Dropbox/My-Research/JB-DW-Collab/Clustering-Selective-Inference/R-Code/paper-code-resubmit/figures-code")
library(ggplot2)
library(patchwork)
library(dplyr)
ev_cat <- NULL
n <- 200
nfeat <- 10
sig <- 1
for(id in 1:4) {
name_of_sim <- paste("../simulation-results/type1-est-n", n, "-q", nfeat, "-pt", id, ".Rdata", sep="")
if(file.exists(name_of_sim)) {
load(name_of_sim)
ev_cat <- rbind(ev_cat, ev)
}
}
ev_cat$len <- rep(NA, nrow(ev_cat))
ev_cat$len[grep("len_2", ev_cat$Model)] <- 2
ev_cat$len[grep("len_4", ev_cat$Model)] <- 4
ev_cat$len[grep("len_6", ev_cat$Model)] <- 6
ev_cat$len <- as.factor(ev_cat$len)
average <- ev_cat[ev_cat$Method == "average-iso-est-test-K-3" & ev_cat$effect == 0, ]
centroid <- ev_cat[ev_cat$Method == "centroid-iso-est-test-K-3" & ev_cat$effect == 0, ]
single <- ev_cat[ev_cat$Method == "single-iso-est-test-K-3" & ev_cat$effect == 0, ]
complete <- ev_cat[ev_cat$Method == "complete-iso-est-test-K-3" & ev_cat$effect == 0, ]
average_filter <- as.data.frame(average %>% group_by(len) %>% slice_head(n=500))
centroid_filter <- as.data.frame(centroid %>% group_by(len) %>% slice_head(n=500))
single_filter <- as.data.frame(single %>% group_by(len) %>% slice_head(n=500))
complete_filter <- as.data.frame(complete %>% group_by(len) %>% slice_head(n=500))
#### QQ Plots ####
p1 <- ggplot(average_filter) +
geom_qq(aes(sample=pval, group=len, colour=len), size=0.5, distribution=qunif) +
geom_abline(slope=1, intercept=0, col="black") +
xlab("Uniform(0, 1) quantiles") +
ylab("Empirical quantiles") + theme_bw(base_size = 15) +
ggtitle("(a) Average linkage")
p2 <- ggplot(centroid_filter) +
geom_qq(aes(sample=pval, group=len, colour=len), size=0.5, distribution=qunif) +
geom_abline(slope=1, intercept=0, col="black") +
xlab("Uniform(0, 1) quantiles") +
ylab("Empirical quantiles") + theme_bw(base_size = 15) +
ggtitle("(b) Centroid linkage")
p3 <- ggplot(single_filter) +
geom_qq(aes(sample=pval, group=len, colour=len), size=0.5, distribution=qunif) +
geom_abline(slope=1, intercept=0, col="black") +
xlab("Uniform(0, 1) quantiles") +
ylab("Empirical quantiles") + theme_bw(base_size = 15) +
ggtitle("(c) Single linkage")
p4 <- ggplot(complete_filter) +
geom_qq(aes(sample=pval, group=len, colour=len), size=0.5, distribution=qunif) +
geom_abline(slope=1, intercept=0, col="black") +
xlab("Uniform(0, 1) quantiles") +
ylab("Empirical quantiles") + theme_bw(base_size = 15) +
ggtitle("(d) Complete linkage")
combined <- (p1 + p2 + p3 + p4) & theme(legend.position = "bottom") &
scale_colour_manual(name=expression("Distance between clusters ("~delta~")"),
values = c("#9ecae1", "#4292c6", "#08519c")) &
guides(colour=guide_legend(nrow=1,byrow=TRUE,
override.aes = list(size=5)))
combined
ggsave(combined + plot_layout(nrow=1, guides = "collect"), file="../figures/FigureS1.pdf",
height=3.5, width=12.5)
